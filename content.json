{"meta":{"title":"张添豪的博客","subtitle":"莫道君行早，人迹板桥霜","description":null,"author":"Coper","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"Linux --基本文本处理","slug":"Linux-基本文本处理","date":"2019-08-20T07:48:47.000Z","updated":"2019-08-20T08:06:55.619Z","comments":true,"path":"2019/08/20/Linux-基本文本处理/","link":"","permalink":"http://yoursite.com/2019/08/20/Linux-基本文本处理/","excerpt":"","text":"1.cd命令:这是一个非常基本, 也是大家经常需要使用的命令, 它用于切换当前目录, 它的参数是要切换到的目录的路径, 可以是绝对路径, 也可以是相对路.如: cd /root/Docements 切换到目录/root/Docements cd ./path 切换到当前目录下的path目录中, “.”表示当前目录 cd ../path 切换到上层目录中的path目录中, “..”表示上一层目录 cd .. 返回上一级 cd - 返回上次所在目录 cd / 返回根目录(绝对路径) 2.ls命令:这是一个非常有用的查看文件与目录的命令, list之意, 它的参数非常多, 下面就列出一些我常用的参数吧, 如下: -l : 列出长数据串, 包含文件的属性与权限数据等 -a : 列出全部的文件, 连同隐藏文件(开头为.的文件)一起列出来(常用) -d : 仅列出目录本身, 而不是列出目录的文件数据 -h : 将文件容量以较易读的方式(GB，kB等)列出来 -R : 连同子目录的内容一起列出(递归列出), 等于该目录下的所有文件都会显示出来 注: 这些参数也可以组合使用,下面举两个例子:12ls -l # 以长数据串的形式列出当前目录下的数据文件和目录ls -lR # 以长数据串的形式列出当前目录下的所有文件 3.grep命令该命令常用于分析一行的信息,显示找到指定信息, 若当中有我们所需要的信息, 就将该行显示出来, 该命令通常与管道命令一起使用, 用于对一些命令的输出进行筛选加工等等, 它的简单语法为:1grep [-acinv] [--color=auto] &apos;查找字符串&apos; filename -a : 将binary文件以text文件的方式查找数据 -c : 计算找到‘查找字符串’的次数 -i :忽略大小写的区别, 即把大小写视为相同 -v :反向选择, 即显示出没有‘查找字符串’内容的那一行12# 取出文件/etc/man.config中包含MANPATH的行，并把找到的关键字加上颜色grep --color=auto &apos;MANPATH&apos; /etc/man.config 12# 把ls -l的输出中包含字母file（不区分大小写）的内容输出ls -l | grep -i file 4.find命令find是一个基于查找的功能非常强大的命令, 相对而言, 它的使用也相对较为复杂, 参数也比较多, 所以在这里将给把它们分类列出, 它的基本语法如下:1find [PATH] [option] [action] 与时间有关的参数：-mtime n : n为数字，意思为在n天之前的”一天内”被更改过的文件;-mtime +n : 列出在n天之前(不含n天本身)被更改过的文件名;-mtime -n : 列出在n天之内(含n天本身)被更改过的文件名；-newer file : 列出比file还要新的文件名 例如:1find /root -mtime 0 # 在当前目录下查找今天之内有改动的文件 与用户或用户组名有关的参数:-user name : 列出文件所有者为name的文件-group name : 列出文件所属用户组为name的文件-uid n : 列出文件所有者为用户ID为n的文件-gid n : 列出文件所属用户组为用户组ID为n的文件 例如:1find /home/ljianhui -user ljianhui # 在目录/home/ljianhui中找出所有者为ljianhui的文件 与文件权限及名称有关的参数： -name filename : 找出文件名为filename的文件 -size [+-]SIZE : 找出比SIZE还要大(+)或小(-)的文件 -tpye TYPE : 查找文件的类型为TYPE的文件, TYPE的值主要有: 一般文件(f)、设备文件(b、c)、目录(d)、连接文件(l)、socket(s)、FIFO管道文件(p); -perm mode : 查找文件权限刚好等于mode的文件, mode用数字表示, 如0755; -perm -mode : 查找文件权限必须要全部包括mode权限的文件, mode用数字表示 -perm +mode :查找文件权限包含任一mode的权限的文件, mode用数字表示 例如:123find / -name passwd # 查找文件名为passwd的文件find . -perm 0755 # 查找当前目录中文件权限的0755的文件find . -size +12k # 查找当前目录中大于12KB的文件，注意c表示byte 5.cp命令该命令用于复制文件, copy之意, 它还可以把多个文件一次性地复制到一个目录下, 它的常用参数如下: -a : 将文件的特性一起复制 -p : 连同文件的属性一起复制, 而非使用默认方式, 与-a相似, 常用于备份 -i : 若目标文件已经存在时, 在覆盖时会先询问操作的进行 -r : 递归持续复制, 用于目录的复制行为 -u : 目标文件与源文件有差异时才会复制 例如:12cp -a file1 file2 #连同文件的所有特性把文件file1复制成文件file2cp file1 file2 file3 dir #把文件file1、file2、file3复制到目录dir中 6. mv命令该命令用于移动文件、目录或更名, move之意, 它的常用参数如下: -f : force强制的意思, 如果目标文件已经存在, 不会询问而直接覆盖 -i : 若目标文件已经存在, 就会询问是否覆盖 -u : 若目标文件已经存在, 且比目标文件新, 才会更新注: 该命令可以把一个文件或多个文件一次移动一个文件夹中, 但是最后一个目标文件一定要是”目录”. 例如:12mv file1 file2 file3 dir # 把文件file1、file2、file3移动到目录dir中mv file1 file2 # 把文件file1重命名为file2 7. rm命令该命令用于删除文件或目录, remove之意, 它的常用参数如下: -f :就是force的意思, 忽略不存在的文件, 不会出现警告消息 -i :互动模式, 在删除前会询问用户是否操作 -r :递归删除, 最常用于目录删除, 它是一个非常危险的参数 例如:12rm -i file # 删除文件file，在删除之前会询问是否进行该操作rm -fr dir # 强制删除目录dir中的所有文件 8. ps命令该命令用于将某个时间点的进程运行情况选取下来并输出, process之意, 它的常用参数如下: -A : 所有的进程均显示出来 -a : 不与terminal有关的所有进程 -u : 有效用户的相关进程 -x : 一般与a参数一起使用，可列出较完整的信息 -l : 较长, 较详细地将PID的信息列出 其实我们只要记住ps一般使用的命令参数搭配即可, 它们并不多, 如下:1234ps aux # 查看系统所有的进程数据ps ax # 查看不与terminal有关的所有进程ps -lA # 查看系统所有的进程数据ps axjf # 查看连同一部分进程树状态 9.kill命令该命令用于向某个工作(%jobnumber)或者是某个PID(数字)传送一个信号,对进程进行终止及处理 它通常与ps和jobs命令一起使用, 它的基本语法如下:1kill -signal PID signal的常用参数如下:注: 最前面的数字为信号的代号,使用时可以用代号代替相应的信号.123451：SIGHUP，启动被终止的进程2：SIGINT，相当于输入ctrl+c，中断一个程序的进行9：SIGKILL，强制中断一个进程的进行15：SIGTERM，以正常的结束进程方式来终止进程17：SIGSTOP，相当于输入ctrl+z，暂停一个进程的进行 例如：以正常的结束进程方式来终止第一个后台工作，可用jobs命令查看后台中的第一个工作进程1kill -SIGTERM %1 重新改动进程ID为PID的进程, PID可用ps命令通过管道命令加上grep命令进行筛选获得1kill -SIGHUP PID 10.killal命令该命令用于向一个命令启动的进程发送一个信号, 它的一般语法如下:1killall [-iIe] [command name] 它的参数如下显示:-i :交互式的意思, 若需要删除时, 会询问用户-e :表示后面接的command name要一致, 但command name不能超过15个字符-I :命令名称忽略大小写 例如:1killall -SIGHUP syslogd # 重新启动syslogd 11.file 命令该命令用于判断接在file命令后的文件的基本数据(判断文件数据类型), 因为在Linux下文件的类型并不是以后缀为分的, 所以这个命令对我们来说就很有用了, 它的用法非常简单, 基本语法如下:1file filename 例如:1file ./test 12.tar命令该命令用于对文件进行打包, 默认情况并不会压缩, 如果指定了相应的参数, 它还会调用相应的压缩程序(如gzip和bzip等)进行压缩和解压. 它的常用参数如下: -c : 新建打包文件 -t : 查看打包文件的内容含有哪些文件名 -x : 解打包或解压缩的功能, 可以搭配-C(大写)指定解压的目录, 注意-c,-t,-x不能同时出现在同一条命令中 -j : 通过bzip2的支持进行压缩/解压缩 -z : 通过gzip的支持进行压缩/解压缩 -v : 在压缩/解压缩过程中, 将正在处理的文件名显示出来 -f filename : filename为要处理的文件 -C dir : 指定压缩/解压缩的目录dir 上面的解说可以已经让你晕过去了, 但是通常我们只需要记住下面三条命令即可:123压缩:tar -jcv -f filename.tar.bz2 要被处理的文件或目录名称查询:tar -jtv -f filename.tar.bz2解压:tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录 注：文件名并不定要以后缀tar.bz2结尾, 这里主要是为了说明使用的压缩程序为bzip2 13.cat命令该命令用于查看文本文件的内容, 后接要查看的文件名, 通常可用管道与more和less一起使用, 从而可以一页页地查看数据. 例如:1cat text | less # 查看text文件中的内容 注：这条命令也可以使用less text来代替14.chgrp命令该命令用于改变文件所属用户组, 它的使用非常简单, 它的基本用法如下:1chgrp [-R] dirname/filename -R : 进行递归的持续对所有文件和子目录更改例如：1chgrp users -R ./dir # 递归地把dir目录下中的所有文件和子目录下所有文件的用户组修改为users 15.chown命令该命令用于改变文件的所有者, 与chgrp命令的使用方法相同, 只是修改的文件属性不同, 不再详述. 16.chmod命令该命令用于改变文件的权限, 一般的用法如下:1chmod [-R] xyz 文件或目录 -R: 进行递归的持续更改, 即连同子目录下的所有文件都会更改同时, chmod还可以使用u(user)、g(group)、o(other)、a(all)和+(加入)、-(删除)、=(设置)跟rwx搭配来对文件的权限进行更改. 例如:12chmod 0755 file # 把file的文件权限改变为-rxwr-xr-x 读取权限r为&quot;4&quot;,写入权限w为&quot;2&quot;,执行或切换权限x为&quot;1&quot;chmod g+w file # 向file的文件权限中加入用户组可写权限 17.vim命令 常用命令: 12345vi filename # 打开已存在的文件或者新建一个文件vi + 行号 filename # 在进入 vi 后，光标处于文件中特定的某行上，可在 vi 命令上加上行号和文件名vi + filename # 如果希望在进入 vi 之后光标处于文件最末行，则只需去掉命令中+后面的数字 n 即可vi +/匹配的关键字 filename # 进入 vi 后，光标就处于文件中第一个与指定模式串相匹配的那行上vi *.filename # 使用 vi 可以同时编辑多个文件，只要在进入 vi 的命令中写入所要操作的文件即可，还可以使用通配符 插入文本命令：i 和 I 12i 命令将文本插入到光标所在位置前I 命令将文本插入当前行的行首。 追加文本命令：a 和 A 12a 命令将新文本追加到光标当前所在位置之后A 命令将新文本追加到所在行的行尾。 空行插入命令：o 和 O 12o 命令将在光标所在行的下面插入一个空行，并将光标置于该行的行首。O 命令在光标所在行的上面插入一个空行，并将光标置于该行的行首。 vi文本删除命令(删除文件内容) 123456x ：每按一次，删除光标所在位置的&quot;后面&quot;一个字符。#x ：例如，「6x」表示删除光标所在位置的&quot;后面&quot;6个字符。X ：大写的X，每按一次，删除光标所在位置的&quot;前面&quot;一个字符。#X ：例如，「20X」表示删除光标所在位置的&quot;前面&quot;20个字符。dd ：删除光标所在行。#dd ：从光标所在行开始删除#行 文本粘贴命令 1p 命令：粘贴命令，粘贴当前缓冲区中的内容。 文本选择命令 12v 命令：在命令模式下进行文本选择。在需要选择的文本的起始处按下 v 键进入块选择模式，然后移动光标到块尾处。这之间的部分被高亮显示，表示被选中。V 命令：在命令模式下按行进行文本选择。在需要选择的文本的第一行按下 V 键，然后移动光标到块的最后一行。 vi撤销命令(u和U), 撤销上一次的操作 123撤销命令分为以下两种u 命令:该命令撤销上一次所做的操作。多次使用 u 命令会一步一步依次撤销之前做过的操作（在一次切换到文本输入模式中输入的所有文本算一次操作）。U 命令:该命令会一次性撤销自上次移动到当前行以来做过的所有操作，再使用一次 U 命令则撤销之前的 U 命令所做的操作，恢复被撤销的内容。 vi退出命令 1234567891011:q 当用户不清楚自己当前编译的文件是否被修改时，可以使用该命令进行测试，而不必担心因为误操作导致文件数据丢失。:q! 该命令不论文件是否改变都会强行退出 vi 编辑器，对于此命令用户应当慎用。:w 新文件名vi 保存当前编辑文件，但并不退出，而是继续等待用户输入命令。在使用 w 命令时，可以再给当前编辑文件起一个新的文件名。这个功能相当于将该文件另存为为一个新的文件。:w! 新文件名说明：该命令与:w命令相同，所不同的是，即使指定的新文件存在，vi 编辑器也会用当前编辑文件对其进行替换，而不再询问用户。:wq vi 将先保存文件，然后退出 vi 返回到 shell。如果当前文件尚未取名，则需要现指定一个文件名。:x 说明：若当前编辑文件曾被修改过，则 vi 会保存该文件。否则 vi 直接退出，不保存该文件。 vi字符替换命令（r和R命令）12345671. r 命令该命令将当前光标所指的字符替换为提供的字符。可以在该命令之前加上数字 n，表示将从当前字符开始的 n 个字符替换为提供的字符2. R命令该命令会让 vi 进入 replace 模式。在此模式下，每个输入的字符都会替换当前光标下的字符，直到输入 &lt;Esc&gt; 结束该模式。 vi字符串检索（查找）命令 1234567891011查找命令有 5 种/string /命令从光标处开始向后寻找字符串 string。?string ? 命令从光标处开始向前寻找字符串 string。n 命令重复上一条检索命令。N 命令重复上一条检索命令，但检索方向改变。例如上次的检索命令是向前检索，那么此次检索的方向是向后；如果上次的检索命令是向后检索，那么此次检索的方向是向前。g/string 检索 string。g/命令使光标停止在第一个检索到的 string 串的行首。 vi字符串替换命令 1[range]s/s1/s2/ [option] [range] 表示检索范围，省略时表示当前行。下面是一些检索范围的例子。 1,10表示从第 1 行到 10 行。%表示整个文件。 . , 从当前行到文件尾。 s 为替换命令。 s1 要被替换的串，s2 为替换的串。option 表示选项： /g表示在全局文件中进行替换。 /c表示在每次替换之前需要用户进行确认。省略时仅对每行第一个匹配串进行替换。 18.time命令该命令用于测算一个命令(即程序)的执行时间. 它的使用非常简单, 就像平时输入命令一样, 不过在命令的前面加入一个time即可, 例如:12time ./processtime ps aux 在程序或命令运行结束后, 在最后输出了三个时间, 它们分别是: user: 用户CPU时间, 命令执行完成花费的用户CPU时间, 即命令在用户态中执行时间总和; system: 系统CPU时间, 命令执行完成花费的系统CPU时间, 即命令在核心态中执行时间总和; real: 实际时间, 从command命令行开始执行到运行终止的消逝时间; 注: 用户CPU时间和系统CPU时间之和为CPU时间, 即命令占用CPU执行的时间总和. 实际时间要大于CPU时间, 因为Linux是多任务操作系统, 往往在执行一条命令时, 系统还要处理其它任务. 另一个需要注意的问题是即使每次执行相同命令, 但所花费的时间也是不一样, 其花费时间是与系统运行相关的.","categories":[],"tags":[]},{"title":"Linux--基本文本处理","slug":"Linux-基本文本处理-1","date":"2019-08-19T08:43:23.000Z","updated":"2019-08-19T08:44:01.422Z","comments":true,"path":"2019/08/19/Linux-基本文本处理-1/","link":"","permalink":"http://yoursite.com/2019/08/19/Linux-基本文本处理-1/","excerpt":"","text":"fold命令&emsp;&emsp;folder指令会从指定的文件里读取内容, 将超过限定列宽的列加入增列字符后, 输出到标准输出设备。若不指定任何文件名称, 或是所给予的文件名为-, 则fold指令会从标准输入设备读取数据。1fold [-bs] [-w &lt;每行列数&gt;] [--help] [--version] [文件...] -b或–bytes:以Byte为单位计算列宽, 而非采用列数编号为单位。 -s或–spaces:以空格字符作为换列点。 &lt;每行列数&gt;-w&lt;每行列数&gt;或–width &lt;每行列数&gt;:设置每行的最大列数。 –help:在线帮助。 –version:显示版本信息。将一个名为testfile的文件的行折叠成宽度为30, 可使用如下命令:1fold -w 30 testfile 为了对比，先将testfile文件输出如下：1234567891011121314$ cat testfile # 查看testfile中的内容Linux networks are becoming more and more common, butsecurity is often an overlookedissue. Unfortunately, in today’s environment all networksare potential hacker targets,from top-secret military research networks to small home LANs.Linux Network Security focuses on securing Linux in anetworked environment, where thesecurity of the entire network needs to be consideredrather than just isolated machines.It uses a mix of theory and practical techniques toteach administrators how to install anduse security applications, as well as how theapplications work and why they are necessary. 然后使用fold命令折叠显示：123456789101112131415161718192021$ fold -w 30 testfile # 行折叠成宽度为30，显示testfile文件Linux networks are becoming more and more common, but security is often an overlooked issue. Unfortunately, in today’senvironment all networks arepotential hacker targets, fromtop-secret military researchnetworks to small home LANs.Linux Network Security focuseson securing Linux in a networked environment, where the security of the entire network needs to be considered rather than just isolated machines. Ituses a mix of theory and practical techniques to teach administrators how to install and use security applications, as well as how the applications work and why they are necessary ####fmt命令&emsp;&emsp;fmt指令会从指定的文件里读取内容, 将其依照指定格式重新编排后, 输出到标准输出设备。若指定的文件名为-, 则fmt指令会从标准输入设备读取数据。1fmt [-cstu] [-w &lt;每行字符数&gt;] [--help] [--version] [文件...] -c或–crown-margin:每段前两列缩排。 -s或–split-only:只拆开字数超出每列字符数的行, 但不合并字数不足每列字符数的行。 -t或–tagged-paragraph:每列前两列缩排, 但第1列和第2列的缩排格式不同。 -u或–uniform-spacing:每个字符之间都以一个空格字符间隔, 每个句子之间则两个空格字符分隔。 -w &lt;每行字符数&gt;:设置每行的最大字符数。 –help:在线帮助。 –version:显示版本信息。先使用cat命令查看文件内容:123456$ cat testfile # 查看testfile文件的内容hello Linux!Linux is a free Unix-type operating system.This is a Linux testfile!LinuxLinux 使用fmt命令重排之后，输出结果如下：123$ fmt -w 85 testfile # 指定重排宽度为85个字符hello Linux! Linux is a free Unix-type operating system. This is a Linux testfile!Linux Linux rev命令&emsp;&emsp;rev命令将文件中的每行内容以字符为单位反序输出, 即第一个字符最后输出, 最后一个字符最先输出, 依次类推.12rev [参数]参数为指定要反序显示内容的文件. ####pr命令&emsp;&emsp;将文本文件内容转换成适合打印的格式: 1pr [选项] [文件] +首页[:末页]、–pages=首页[:末页]: 在指定的首页/末页处开始/停止打印. -列数、–columns=列数: 输出指定的列数. 如果指定了-a选项, 则从上到下列印. 程序会自动在每一页均衡每列占用的行数. -a、–across: 设置每列从上到下输出, 配合-列数选项一起使用. -c、–show-control-chars: 使用头标^G和八进制反斜杠标记。 -d、–double-space: 加倍输出空白区域。 -D、–date-format=格式: 使用遵循指定格式的页眉日期. -e[字符[宽度]]、–expand-tabs[=字符[宽度]]:扩展输入的字符(TAB)到制表符宽度(8). -F、-f、–form-feed: 使用出纸页页标代替新行作为页面间的分隔符(使用-F选项时报头为3行, 不使用时为5行). -h、–header=页眉: 在页眉中使用居中的指定字符代替文件名, -h “”输出一个空行, 不要使用-h””. -i[字符[宽度]]、–output-tabs[=字符[宽度]]:使用指定字符(或TAB)代替空格不足到指定制表符宽度(默认8). -J、–join-lines: 合并整个行, 关闭-W选项的行截断, 不使用栏调整, 使用–sep-string[=字符串]设置分隔符. -l、–length=页长: 使用指定页长的行数(默认66)(默认文本行数为56，当启用-F时为63). -m、–merge: 在同一行显示所有文件, 每个文件占用一栏, 分割行, 但是当使用-J时将行合并到完整长度. -n[分隔符[位数]]、–number-lines[=分隔符[位数]]:显示行号, 使用指定(默认5)位数, 后接分隔符(默认TABM), 默认从输入文件的第一行开始计数. -N、–first-line-number=数字: 从首页的首行以指定数字开始计数. -o、–indent=缩进量: 将每行缩进(默认0)个空格, 不影响-w或-W参数, 缩进量的值将被加入页面宽度. -r、–no-file-warnings: 当文件无法打开时忽略警告. -s[CHAR]、–separator[=CHAR]: 由单个字符分隔各列, 未附加-w时默认为制表符, 否则为空. 另外除非-w选项被指定，否则-s[CHAR]会屏蔽三个列相关的截行选项(-COLUMN|-a -COLUMN|-m). -S字符串、–sep-string[=字符串]: 使用指定的字符串分栏, 不使用-S则使用默认的制表符TAB作为分隔符, 与-J和空格一起使用(等于-S” “)对分栏选项无影响. -t、–omit-header: 忽略页眉和页脚. -T、–omit-pagination: 按照输入文件中的设置忽略页眉和页脚并除去所有分页记号. -v、–show-nonprinting: 使用八进制反斜杠标记. -w、–width=页面宽度: 为多栏页面输出将设置为指定的字符数(默认72), 仅当-s[char]选项不启用时有效(即保持默认值72). -W、–page-width=页宽: 总是将页宽设置为指定的(默认72)字符数，除非-J选项启用总是截断行, 此参数与-S或-s冲突. –help: 显示此帮助信息并退出. –version: 显示版本信息并退出.如果页长小于等于10, 则使用-t选项. 如果FILE没有定义或者FILE是-, 则从标准输入读入. ####sort命令&emsp;&emsp;sort命令是依据不同的数据类型进行排序:1sort [-bcfMnrtk] [源文件] [-o 输出文件] sort可针对文本文件的内容以行为单位来排序. -b:忽略每行前面开始出的空格字符. -c:检查文件是否已经按照顺序排序. -f:排序时，忽略大小写字母. -M:将前面3个字母依照月份的缩写进行排序. -n:依照数值的大小排序. -o &lt;输出文件&gt;:将排序后的结果存入指定的文件. -r:以相反的顺序来排序. -t &lt;分隔字符&gt;:指定排序时所用的栏位分隔字符. -k:选择以哪个区间进行排序.下面通过几个例子来讲述sort的使用: sort将文件的每一行作为一个单位, 相互比较, 比较原则是从首字符向后, 依次按ASCII码值进行比较, 最后将它们按升序输出.12345678910$ cat seq.txtbananaapplepearorange$ sort seq.txtapplebananaorangepear 用户可以保存排序后的文件内容, 或把排序后的文件内容输出至打印机. 下例中用户把排序后的文件内容保存到名为result的文件中:1sort seq.txt &gt; result &emsp;&emsp;2. sort的-u选项作用很简单, 就是在输出中去除重复行. 3. sort默认的排序方式是升序, 如果想改成降序, 就加个-r就搞定了. 4. sort默认是把结果输出到标准输出, 所以需要用重定向才能将结果写入文件, 例如sort filename &gt; newfile.但如果你想把排序结果输出到原文件中, 用重定向可就不行了, 而-o选项就是为了解决这一问题. 5. -n选项告诉sort要以数值来排序. 6. sort的-t和-k选项:如果有一个文件的内容是这样:1234banana:30:5.5apple:10:2.5pear:90:2.3orange:20:3.4 这个文件有三列, 列与列之间用冒号隔开. 第一列表示水果类型, 第二列表示水果数量, 第三列表示水果价格. 那么我想以水果数量来排序, 也就是以第二列来排序, 如何利用sort实现?幸好, sort提供了-t选项, 后面可以设定间隔符. 指定了间隔符之后, 就可以用-k来指定列数了.12345$ sort -n -k 2 -t : facebook.txtapple:10:2.5orange:20:3.4banana:30:5.5pear:90:2.3 &emsp;&emsp;7. 其他的sort常用选项: -i:仅仅比较可打印字符. -R:根据哈希值随机排序. -m:仅仅合并已经排序好的文件, 不执行排序操作.补充说明: 在sort命令中, 一个文本行最多包含10列. -k选项的语法为-k pos1[, pos2]，pos1表示开始列, pos2表示结束列; -k pos表示从pos列开始一直到文本列的结束; -k pos,pos表示在第pos列. -r选项是对所有的关键字进行降序排序, 而-k pos1(r)[,pos2(r)]是对特定的关键字进行降序排序.-n和-r具有类似的属性. -k选项能够使用多个修饰符, 例如-k pos1(nr)[,pos2(nr)]. wc命令&emsp;&emsp;利用wc命令我们可以计算文件的Byte数、字数、或是列数. 若不指定文件名称、或是所给予的文件名为,则wc命令会从标准输入设备读取数据.1wc [-clw] [--help] [--version] [文件...] -c、–bytes或–chars:只显示Bytes数. -l或–lines:只显示列数. -w或–words:只显示字数. –help:在线帮助. –version:显示版本信息.先查看testfile文件的内容:12345678$ cat testfileLinux networks are becoming more and more common, but scurity is often an overlookedissue. Unfortunately, in today’s environment all networks are potential hacker targets,fro0m tp-secret military research networks to small home LANs.Linux Network Securty focuses on securing Linux in a networked environment, where thesecurity of the entire network needs to be considered rather than just isolated machines.It uses a mix of theory and practicl techniques to teach administrators how to install anduse security applications, as well as how the applcations work and why they are necesary. 使用wc统计:12$ wc testfile # testfile文件的统计信息3 92 598 testfile # testfile文件的行数为3、单词数92、字节数598 ####cut命令&emsp;&emsp;cut是一个选取命令, 就是将一段数据经过分析, 取出我们想要的. 一般来说, 选取信息通常是针对行来进行分析的, 并不是整篇信息分析的.123cut [-bn] [file]cut [-c] [file]cut [-df] [file] cut命令从文件的每一行剪切字节、字符和字段并将这些内容写至标准输出. 如果不指定File参数, cut命令将读取标准输入. -b:以字节为单位进行分割. 这些字节位置将忽略多字节字符边界, 除非也指定了-n标志. -c:以字符为单位进行分割. -d:自定义分隔符, 默认为制表符. -f:与-d一起使用, 指定显示哪个区域. -n:取消分割多字节字符, 仅和-b标志一起使用. -s:不输出不包含列分隔符的行.cut命令主要是接受三个定位方法: 字节(bytes)用选项-b, 字符(characters)用选项-c, 域(fields)用选项-f. cut -b 3 # 如果想提取每一行的第3个字节cut -b 3-5,8 # 如果想提取第3、第4、第5和第8个字节，注意顺序不能颠倒cut -b -3 # 表示从第一个字节到第三个字节cut -b 3- # 表示从第三个字节到行尾当遇到多字节字符时, 可以使用-n选项, -n用于告诉cut不要将多字节字符拆开. 为什么会有域的提取呢？因为刚才提到的-b和-c只能在固定格式的文档中提取信息, 而对于非固定格式的信息则束手无策,这时候域就派上用场了. 如果你观察过/etc/passwd文件就会发现, 它并不像who的输出信息那样具有固定格式, 而是比较零散的排放. 但是冒号在这个文件的每一行中都起到了非常重要的作用, 冒号用来隔开每一个项. cut命令提供了这样的提取方式, 具体的说就是设置间隔符, 再设置提取第几个域就OK了. 以/etc/passwd的前五行内容为例:123456$ cat /etc/passwd | head -n 5root:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 123456$ cat /etc/passwd | head -n 5 | cut -d : -f 1rootbindaemonadmlp 用-d来设置间隔符为冒号, 然后用-f来设置要取的是第一个域, 于是所有的用户名就都列出来了！当然, 在设定-f时也可以使用例如3-5或者4-类似的格式. ####paste命令&emsp;&emsp;paste命令会把每个文件以列对列的方式, 一列列地加以合并.1paste [-s] [-d &lt;间隔字符&gt;] [--help] [--version] [文件] -d &lt;间隔字符&gt;或–delimiters=&lt;间隔字符&gt;:用指定的间隔字符取代跳格字符. -s或–serial:串列进行而非平行处理。 –help:在线帮助。 –version:显示帮助信息。使用paste指令将文件file、testfile和testfile1进行合并. 首先使用cat命令查看3个文件内容:123456789$ cat file # file文件的内容xiongdan 200lihaihui 233lymlrl 231$ cat testfile # testfile文件的内容liangyuanm ss$ cat testfile1 # testfile1文件的内容huanggai 56zhixi 73 当合并指令执行后, 程序界面中将显示合并后的文件内容:123456xiongdan 200lihaihui 233lymlrl 231liangyuanm sshuanggai 56zhixi 73 若使用paste指令的参数-s, 则可以将一个文件中的多行数据合并为一行进行显示. 例如, 将文件file中的3行数据合并为一行数据进行显示:1paste -s file # 合并指定文件的多行数据 上面的命令执行后, 显示的数据内容如下:1xiongdan 200 lihaihui 233 lymlrl 231 注意, 参数-s只是将testfile文件的内容调整显示方式, 并不会改变原文件的内容格式. join命令&emsp;&emsp;join命令用于将两个文件中指定列位内容相同的行加以合并, 再输出到标准输出设备:12join [-i] [-a&lt;1或2&gt;] [-e &lt;字符串&gt;] [-o &lt;格式&gt;] [-t &lt;字符&gt;] [-v &lt;1或2&gt;] \\ [-1 &lt;列位&gt;] [-2 &lt;列位&gt;] [--help] [--version] [文件1] [文件2] -a &lt;1或2&gt;: 除了显示原来的输出内容之外, 还显示指令文件中没有相同栏位的行. -e &lt;字符串&gt;: 若文件1与文件2中找不到指定的栏位, 则在输出中填入选项中的字符串. -i或–igore-case: 比较栏位内容时, 忽略大小写的差异. -o &lt;格式&gt;: 按照指定的格式来显示结果. -t &lt;字符&gt;: 使用栏位的分隔字符. -v &lt;1或2&gt;: 跟-a相同, 但是只显示文件中没有相同栏位的行. -1 &lt;列位&gt;: 连接文件1指定的栏位. -2 &lt;列位&gt;: 连接文件2指定的栏位. –help: 显示帮助. –version: 显示版本信息. 首先查看testfile_1、testfile_2中的文件内容:1234$ cat testfile_1 # testfile_1文件中的内容Hello 95 # 例如, 本例中第一列为姓名, 第二列为数额Linux 85test 30 1234$ cat testfile_2 # testfile_2文件中的内容Hello 2005 # 例如, 本例中第一列为姓名, 第二列为年份Linux 2009test 2006 然后以默认的方式比较两个文件, 将两个文件中指定字段的内容相同的行连接起来, 在终端中输入命令:1$ join testfile_1 testfile_2 # 连接testfile_1、testfile_2中的内容 123Hello 95 2005 # 连接后显示的内容Linux 85 2009test 30 2006 文件1与文件2的位置对输出到标准输出的结果是有影响的. 例如将命令中的两个文件互换:1$ join testfile_2 testfile_1 # 改变文件顺序连接两个文件 123Hello 2005 95 # 连接后显示的内容Linux 2009 85test 2006 30 tr命令&emsp;&emsp;通过使用tr, 可以非常容易地实现sed许多最基本功能, 可以将tr看作为sed的简化的变体: 它可以用一个字符来替换另一个字符, 或者可以完全除去一些字符, 也可以用它来除去重复字符. tr用来从标准输入中通过替换或删除操作进行字符转换,tr主要用于删除文件中控制字符或进行字符转换. 使用tr时要转换两个字符串: 字符串1用于查询, 字符串2用于处理各种转换. tr刚执行时, 字符串1中的字符被映射到字符串2中的字符, 然后转换操作开始.1tr -c -d -s [&quot;string1_to_translate_from&quot;] [&quot;string2_to_translate_to&quot;] &lt; input-file -c: 用字符串1中字符集的补集替换此字符集, 要求字符集为ASCII. -d: 删除字符串1中所有输入字符. -s: 删除所有重复出现字符序列, 只保留第一个; 即将重复出现字符串压缩为一个字符串. input-file: 它是转换文件名. 指定字符串1或字符串2的内容时, 只能使用单字符或字符串范围或列表. [a-z]: a至z内的字符组成的字符串. [A-Z]: A至Z内的字符组成的字符串. [0-9]: 数字串. \\octal:一个三位的八进制数, 对应有效的ASCII字符. [On]:表示字符O重复出现指定次数n, 因此[O2]匹配OO的字符串. 将文件file中出现的abc替换为xyz:1cat file | tr &quot;abc&quot; &quot;xyz&quot; &gt; new_file 注意，这里凡是在file中出现的a都替换成x, b替换为y, c替换为z, 而不是将字符串abc替换为字符串xyz. 使用tr命令统一字母大小写: 12cat file | tr [a-z] [A-Z] &gt; new_file # 小写 -&gt; 大写cat file | tr [A-Z] [a-z] &gt; new_file # 大写 -&gt; 小写 把文件中的数字0至9替换为a至j: 1cat file | tr [0-9] [a-j] &gt; new_file 删除文件file中出现的Snail字符: 1cat file | tr -d &quot;Snail&quot; &gt; new_file 注意，这里凡是在file文件中出现的S、n、a、i和l字符都会被删除, 而不是仅仅删除出现的Snail字符串. 删除文件file中出现的换行\\n、制表\\t字符:1cat file | tr -d &quot;\\n\\t&quot; &gt; new_file 不可见字符都得用转义字符来表示的, 这个都是统一的. 删除连续的重复字母, 只保留第一个: 1cat file | tr -s [a-zA-Z] &gt; new_file 删除空行: 1cat file | tr -s &quot;\\n&quot; &gt; new_file 删除Windows文件造成的^M字符: 123cat file | tr -d &quot;\\r&quot; &gt; new_file# 或者cat file | tr -s &quot;\\r&quot; &quot;\\n&quot; &gt; new_file 注意，这里-s后面是两个参数\\r和\\n, 用后者替换前者. 用空格符\\040替换制表符\\011:1cat file | tr -s &quot;\\011&quot; &quot;\\040&quot; &gt; new_file 把路径变量中的冒号:替换成换行符\\n:1echo $PATH | tr -s &quot;:&quot; &quot;\\n&quot;","categories":[],"tags":[]},{"title":"python --zip","slug":"python-zip-0","date":"2019-08-14T10:11:42.000Z","updated":"2019-08-16T09:06:05.726Z","comments":true,"path":"2019/08/14/python-zip-0/","link":"","permalink":"http://yoursite.com/2019/08/14/python-zip-0/","excerpt":"","text":"zip()函数介绍: zip()函数接受0个或多个序列作为参数, 返回一个tuple列表. zip()函数具体的工作机制是, 将每个列表中同一位置的元素取出来组成一个元组, 存放到一个列表中, 然后返回这个列表. 举例说明:123456&gt;&gt;&gt; x = [1,2,3]&gt;&gt;&gt; y = ['a','b','c']&gt;&gt;&gt; z = [4,5,6]&gt;&gt;&gt; zip_xyz = zip(x, y, z)&gt;&gt;&gt; print (list(zip_xyz))[(1, 'a', 4), (2, 'b', 5), (3, 'c', 6)] 对于长度不同的seq, zip()函数又怎么处理呢?12345&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b = [4,5,6,7]&gt;&gt;&gt; zip_ab = zip(a, b)&gt;&gt;&gt; print (list(zip_ab))[(1, 4), (2, 5), (3, 6)] 从上面的例子可以看出, 当seq的长度不一致时, zip()会以最短的那个seq为主, 进行处理, 然后将多余的舍弃掉. zip()对只有一个seq的处理:1234&gt;&gt;&gt; c = ['a', 'b', 'c']&gt;&gt;&gt; zip_c = zip(c)&gt;&gt;&gt; print (list(zip_c))[('a',), ('b',), ('c',)] 我们再看一个例子:123456&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = ['a', 'b', 'c']&gt;&gt;&gt; zip_ab = zip(a,b)&gt;&gt;&gt; un_zip = zip(*zip_ab)&gt;&gt;&gt; print (list((un_zip))[(1, 2, 3), ('a', 'b', 'c')] 一般认为这是一个unzip过, 工作原理如下: 在运行zip(zip_ab)之前, zip_ab的值是:[(1, ‘a’), (2, ‘b’), (3, ‘c’)], 而zip(zip_ab)就等价zip((1, ‘a’), (2, ‘b’), (3, ‘c’)), 所以得出结果：[(1, 2, 3), (‘a’, ‘b’, ‘c’)]. 再来看一个例子:1234&gt;&gt;&gt; x = [1,'a','b']&gt;&gt;&gt; zip_rx = zip(* [x] * 3)&gt;&gt;&gt; print (list(zip_rx))[(1, 1, 1), ('a', 'a', 'a'), ('b', 'b', 'b')] 首先 [x]生成一个列表的列表: [1, ‘a’, ‘b’]，这个列表中只有一个元素[1,’a’,’b’] 其次[x] * 3, 表示将列表中的元素打印三次, 即生成了含有三个元素的列表: [1, ‘a’, ‘b’], [1, ‘a’, ‘b’], [1, ‘a’, ‘b’] 最后是zip( [x] 3)就等价于 zip([1, ‘a’, ‘b’], [1, ‘a’, ‘b’], [1, ‘a’, ‘b’]) 注意:在函数调用中, 使用*list/tuple的方式表示将list/tuple分开, 作为位置参数传递给对应函数, 但前提是对应函数必须支持不定个数的位置参数.","categories":[],"tags":[]},{"title":"Image EdgeDetection Canny","slug":"Image-EdgeDetection-Canny-1","date":"2019-08-12T10:07:37.000Z","updated":"2019-08-19T05:03:14.412Z","comments":true,"path":"2019/08/12/Image-EdgeDetection-Canny-1/","link":"","permalink":"http://yoursite.com/2019/08/12/Image-EdgeDetection-Canny-1/","excerpt":"","text":"图像处理之Canny边缘检测理论介绍:Canny边缘检测是一种流行的边缘检测算法. 它由John F. Canny于1986年开发. 它是一个多阶段算法, 我们将经历每个阶段. 降噪由于边缘检测易受图像中的噪声影响, 因此第一步是使用5x5高斯滤波器去除图像中的噪. 寻找图像的强度梯度然后在水平和垂直方向上用Sobel内核对平滑后的图像进行滤波, 以获得水平方向$(G_{x})$和垂直方向$(G_{y})$的一阶导数. 从这两个图像中, 我们可以找到每个像素的边缘梯度和方向, 渐变方向始终垂直于边缘. 边缘方向角度四舍五入为四个角度中的一个, 表示垂直, 水平和两个对角线(0°,45°,90°和135°). 落入每个颜色区域的边缘方向将被设置为特定角度值,例如, 在[0°,22.5°]或[157.5°,180°]中的θ映射到0°. 如下所示$$EdgeGradient(G)= \\sqrt {G_x ^ 2 + G_y ^ 2}\\Angle(\\theta)= \\tan^{-1}(\\frac {G_y} {G_x})$$ 非最大抑制应用梯度计算后, 从梯度值中提取的边缘仍然非常模. 关于标准3, 应该只对边缘有一个准确的响应. 因此, 非最大抑制可以帮助抑制所有梯度值(通过将它们设置为0), 除了局部最大值, 其指示具有最强烈的强度值变化的位置. 梯度图像中每个像素的算法是: 将当前像素的边缘强度与正和负梯度方向上的像素的边缘强度进行比较. 如果当前像素的边缘强度与具有相同方向的掩模中的其他像素相比是最大的(例如, 指向y方向的像素将与垂直轴上方和下方的像素进行比较), 该值将被保留. 否则, 该值将被抑制. 滞后阈值这个阶段决定哪些边缘都是边缘, 哪些边缘不是边缘. 为此, 我们需要两个阈值, minVal和maxVal. 强度梯度大于maxVal的任何边缘肯定是边缘, 而minVal以下的边缘肯定是非边缘, 因此被丢弃. 位于这两个阈值之间的人是基于其连通性的分类边缘或非边缘. 如果它们连接到“可靠边缘”像素, 则它们被视为边缘的一部分. 否则, 他们也被丢弃.边缘A高于maxVal, 因此被视为”确定边缘”. 虽然边C低于maxVal, 但它连接到边A, 因此也被视为有效边, 我们得到完整的曲线. 但是边缘B虽然高于minVal并且与边缘C的区域相同, 但它没有连接到任何”可靠边缘”, 因此被丢弃. 因此, 我们必须相应地选择minVal和maxVal才能获得正确的结果. 算法原型:&emsp;&emsp;在OpenCV-Python中Canny函数的原型为:1edge = cv2.Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient ]]]) 必要参数: 第一个参数是需要处理的原图像, 该图像必须为单通道的灰度图; 第二个参数是minVal, 最小边缘阈值 第三个参数是maxVal, 最大边缘阈值 推荐的minVal和maxVal阈值之间的比例为1:3或者1:2, 可选参数中apertureSize就是Sobel算子的大小. 而L2gradient参数是一个布尔值, 如果为真, 则使用更精确的L2范数进行计算(即两个方向的倒数的平方和再开放), 否则使用L1范数(直接将两个方向导数的绝对值相加). 代码展示:import cv2 import numpy as np from matplotlib import pyplot as plt img = cv2.imread('messi5.jpg',0) edges = cv2.Canny(img,100,200) plt.subplot(121),plt.imshow(img,cmap = 'gray') plt.title('Original Image'), plt.xticks([]), plt.yticks([]) plt.subplot(122),plt.imshow(edges,cmap = 'gray') plt.title('Edge Image'), plt.xticks([]), plt.yticks([]) plt.show() 结果展示:原始图像:处理后图像:","categories":[],"tags":[]},{"title":"Image EdgeDetection Sobel","slug":"Image-EdgeDetection-Sobel","date":"2019-08-09T10:13:19.000Z","updated":"2019-08-12T01:13:01.618Z","comments":true,"path":"2019/08/09/Image-EdgeDetection-Sobel/","link":"","permalink":"http://yoursite.com/2019/08/09/Image-EdgeDetection-Sobel/","excerpt":"","text":"图像处理之Sobel算子算法原型:&emsp;&emsp;Sobel算子依然是一种过滤器，只是其是带有方向的。在OpenCV-Python中，使用Sobel的算子的函数原型如下:1dst = cv2.Sobel(src, ddepth, dx, dy[, ksize[, scale[, delta[, borderType]]]]])) 前四个是必须的参数: 第一个参数是需要处理的图像； 第二个参数是图像的深度，如cv2.CV_16S, cv2.CV_64F。目标图像的深度必须大于等于原图像的深度； 第三个dx和dy表示的是求导的阶数，0表示这个方向上没有求导，一般为0、1、2。 其后是可选的参数: ksize是Sobel算子的大小，必须为1、3、5、7。 scale是缩放导数的比例常数，默认情况下没有伸缩系数； delta是一个可选的增量，将会加到最终的dst中，同样，默认情况下没有额外的值加到dst中； borderType是判断图像边界的模式。这个参数默认值为cv2.BORDER_DEFAULT。 代码展示:123456789101112131415161718192021 #coding=utf-8import cv2import numpy as np img = cv2.imread(\"D:/lion.jpg\", 0) x = cv2.Sobel(img,cv2.CV_16S,1,0)y = cv2.Sobel(img,cv2.CV_16S,0,1) absX = cv2.convertScaleAbs(x) # 转回uint8absY = cv2.convertScaleAbs(y) dst = cv2.addWeighted(absX,0.5,absY,0.5,0) cv2.imshow(\"absX\", absX)cv2.imshow(\"absY\", absY) cv2.imshow(\"Result\", dst) cv2.waitKey(0)cv2.destroyAllWindows() 注释:&emsp;&emsp;在Sobel函数的第二个参数这里使用了cv2.CV_16S。因为OpenCV文档中对Sobel算子的介绍中有这么一句：“in the case of 8-bit input images it will result in truncated derivatives”。即Sobel函数求完导数后会有负值，还有会大于255的值。而原图像是uint8，即8位无符号数，所以Sobel建立的图像位数不够，会有截断。因此要使用16位有符号的数据类型，即cv2.CV_16S。 &emsp;&emsp;在经过处理后，别忘了用convertScaleAbs()函数将其转回原来的uint8形式。否则将无法显示图像，而只是一副灰色的窗口。convertScaleAbs()的原型为:1dst = cv2.convertScaleAbs(src[, dst[, alpha[, beta]]]) 其中可选参数alpha是伸缩系数，beta是加到结果上的一个值。结果返回uint8类型的图片。 &emsp;&emsp;由于Sobel算子是在两个方向计算的，最后还需要用cv2.addWeighted(…)函数将其组合起来。其函数原型为:1dst = cv2.addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype]]) 其中alpha是第一幅图片中元素的权重，beta是第二个的权重，gamma是加到最后结果上的一个值。 结果展示:原始图像:处理后的图像","categories":[],"tags":[]},{"title":"LSTM Neural Network","slug":"LSTM Neural Network","date":"2019-07-29T07:33:15.000Z","updated":"2019-08-12T05:59:49.636Z","comments":true,"path":"2019/07/29/LSTM Neural Network/","link":"","permalink":"http://yoursite.com/2019/07/29/LSTM Neural Network/","excerpt":"","text":"LSTM Network 长短期时间序列模型介绍核心算法介绍:传统的RNN神经网络:&emsp;&emsp;RNN之所以称为循环神经网络，即”一个序列的当前输出与前面的输出是有相关性”。具体实质体现在后面层数的输入值要加入前面层的输出值，即隐藏层之间不再是不相连的而是有连接的。 展开的递归循环神经网络&emsp;&emsp;在学习信息情况下，如果相关信息与所需信息之间的差距很小，则RNN可以学习使用过去的信息，表现出较好的训练能力，比如：我们试图预测”云在天空中”的最后一次”天空”,RNN模型就能非常容易的识别出来。但是，如果相关信息与所需要信息之间的距离相差过远时，RNN模型就会很难学习连接这些关系。 LSTM 神经网络:&emsp;&emsp; 长短期时间序列模型(LSTM)是一种特殊的RNN，能够学习长期的依赖性。LSTM的优点就是能够明确旨在避免长期依赖性问题。它能够长时间记住信息，解决了RNN信息距离过长而丧失学习的能力的缺点。所有递归神经网络都具有具有神经网络重复模块链的形式。在标准的RNN中，该重复模块具有非常简单的结构，就是单一的tanh层。 标准RNN中的重复模块包含单个层&emsp;&emsp;同样LSTM也具有这种类似链的结构，但是重复模块缺失具有不同的结构，它们分别是传输层，遗忘门，输入门，输出门。LSTM中的重复模块包含四个交互层 1.传输层&emsp;&emsp;传输层水平贯穿图的顶部，直接沿着整个链运行，进行着一些次要的线性交互。从上图中我们可以看出，每个序列索引位置t时刻向前传播中除了和RNN一样具有隐藏状态$h^{(t)}$,还多了另一个隐藏状态，图中上面的横线我们一般称为细胞状态，记为$C^{(t)}$。 传输层中的细胞状态 2.遗忘门&emsp;&emsp;遗忘门是以一定的概率控制是否遗忘上一层的隐藏细胞状态。图中我们可以看出输入的有上一序列的隐藏状态$h^{(t-1)}$和本序列数据$x^{(t)}$,通过激活函数sigmoid，得到遗忘门的输出$f(t)$.由于sigmoid函数的输出$f(t)$是位于[0,1]之间，所以这里的输出$f(t)$就是代表了能否遗忘上一层隐藏细胞状态的概率。该数字表达可以为:$$f^{(t)}=\\sigma(W_{f}h^{(t-1)}+U_{f}x{(t)}+b_{f})$$ 其中$W_{f}$,$U_{f}$,$b_{f}$分别为线性关系的权重和偏移值。 遗忘门的体系架构 3.输入门输入门层决定我们在单元状态中存储哪些新的信息。其中有两部分组成，一部分称为”输入门层的sigmoid层”,这层决定我们将更新之前的哪些值，输出为$i^{(t)}$，第二部分为”输入门层的tanh层”,这层决定我们创建新的候选值,输出为$a^{(t)}$，最后结合两个创建状态进行更新。该数学表达式可以为:$$i^{(t)}=\\sigma(W_{i}h^{(t-1)}+U_{i}x{(t)}+b_{i})\\a^{(t)}=\\tanh(W_{a}h^{(t-1)}+U_{a}x{(t)}+b_{a})$$其中$W_{i}$,$U_{i}$,$b_{i}$,$W_{a}$,$U_{a}$,$b_{a}$分别为线性关系的权重和偏移值。 输入门的体系架构 4.细胞状态更新此过程是决定将旧的细胞状态$C_{t-1}$更新至新的细胞状态$C_{t}$。在这个过程中首先我们将$f_{t}$乘以$C_{t-1}$来决定是否忘记之前的事情。其次我们添加了$i_{t}*\\tilde{C_{t}}$来决定我们需要更新多少新的状态值。即：$$C^{(t)}=C^{(t-1)}\\odot f^{(t)}+i^{(t)}\\odot a^{(t)}$$ 细胞状态更新体系架构 5.输出门输出门是决定我们要输出的内容。首先，先运行的是一个sigmoid层，决定输出的单元状态属于隐藏状态部分$h^{(t-1)}$,还是本序列数据部分$x^{(t)}$.接着，运行的是tan层，将细胞状态$C_{t}$乘以sigmoid层的输出，从而获取我们所决定的部分。即：$$o^{(t)}=\\sigma(W_{o}h^{(t-1)}+U_{o}x^(t)+b_{o})\\h^{(t)}= o^{(t)}\\odot\\tanh(C^{(t)})$$同理其中的$W_{o}$,$U_{o}$,$b_{o}$分别为线性关系的权重和偏移值。 输出门的体系架构 Keras LSTM 算法模型：LSTM模型构建: 1.首先初始化模型Sequential() 2.接着添加LSTM模型层架构，其中$hiddenLayer$代表为隐藏神经元个数，通俗易懂的解释可以为模型中每个sigmoid层或者tanh层。(注意:LSTM训练模型格式矩阵内容[samples,time_steps,features],简单的说就是[n,1,m]架构，即规定了多少特征输入，一个输出) 3.添加模型全连接层 4.编译模型，选择对应的损失函数和优化器，其中常用的损失函数是MSE,MAE–用于回归，binary-crossentropy–用于二值化分类，categorical-crossentropy–用于标签分类。优化的选择我们常用的自适应学习率优化算法 AdaGrad, AdaDelta,Adam。其他类型不建议使用。 1234model = Sequential()model.add(LSTM(hiddenLayer, input_shape=(train_x.shape[1], train_x.shape[2])))model.add(Dense(1))model.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"]) LSTM模型训练: 将设置好的LSTM模型进行训练，其中$epochs$为循环迭代的次数，$batch size$即每次循环所走的分支数，$validation data$即采用交叉验证的方式对数据进行验证1234567891011121314# Fit networkcheckpointer = ModelCheckpoint(filepath=outputModel, verbose=1, save_best_only=True)history = model.fit( train_x, train_y, epochs=epochs, batch_size=batchSize, validation_data=(test_x, test_y), verbose=2, shuffle=False, callbacks=[checkpointer],)logger.info(model.summary())show_picture(history, imageFolder) LSTM模型预测: 模型预测后的得到的结果为[n,1,m]类型，需要重新reshape得到最终的结果1yhat = model.predict(test_X)","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2019-04-30T03:46:04.519Z","updated":"2019-04-30T03:46:04.519Z","comments":true,"path":"2019/04/30/hello-world/","link":"","permalink":"http://yoursite.com/2019/04/30/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}