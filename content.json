{"meta":{"title":"张添豪的博客","subtitle":"莫道君行早，人迹板桥霜","description":null,"author":"Coper","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"Image EdgeDetection Sobel","slug":"Image-EdgeDetection-Sobel","date":"2019-08-09T10:13:19.000Z","updated":"2019-08-12T01:13:01.618Z","comments":true,"path":"2019/08/09/Image-EdgeDetection-Sobel/","link":"","permalink":"http://yoursite.com/2019/08/09/Image-EdgeDetection-Sobel/","excerpt":"","text":"图像处理之Sobel算子算法原型:&emsp;&emsp;Sobel算子依然是一种过滤器，只是其是带有方向的。在OpenCV-Python中，使用Sobel的算子的函数原型如下:1dst = cv2.Sobel(src, ddepth, dx, dy[, ksize[, scale[, delta[, borderType]]]]])) 前四个是必须的参数: 第一个参数是需要处理的图像； 第二个参数是图像的深度，如cv2.CV_16S, cv2.CV_64F。目标图像的深度必须大于等于原图像的深度； 第三个dx和dy表示的是求导的阶数，0表示这个方向上没有求导，一般为0、1、2。 其后是可选的参数: ksize是Sobel算子的大小，必须为1、3、5、7。 scale是缩放导数的比例常数，默认情况下没有伸缩系数； delta是一个可选的增量，将会加到最终的dst中，同样，默认情况下没有额外的值加到dst中； borderType是判断图像边界的模式。这个参数默认值为cv2.BORDER_DEFAULT。 代码展示:123456789101112131415161718192021 #coding=utf-8import cv2import numpy as np img = cv2.imread(\"D:/lion.jpg\", 0) x = cv2.Sobel(img,cv2.CV_16S,1,0)y = cv2.Sobel(img,cv2.CV_16S,0,1) absX = cv2.convertScaleAbs(x) # 转回uint8absY = cv2.convertScaleAbs(y) dst = cv2.addWeighted(absX,0.5,absY,0.5,0) cv2.imshow(\"absX\", absX)cv2.imshow(\"absY\", absY) cv2.imshow(\"Result\", dst) cv2.waitKey(0)cv2.destroyAllWindows() 注释:&emsp;&emsp;在Sobel函数的第二个参数这里使用了cv2.CV_16S。因为OpenCV文档中对Sobel算子的介绍中有这么一句：“in the case of 8-bit input images it will result in truncated derivatives”。即Sobel函数求完导数后会有负值，还有会大于255的值。而原图像是uint8，即8位无符号数，所以Sobel建立的图像位数不够，会有截断。因此要使用16位有符号的数据类型，即cv2.CV_16S。 &emsp;&emsp;在经过处理后，别忘了用convertScaleAbs()函数将其转回原来的uint8形式。否则将无法显示图像，而只是一副灰色的窗口。convertScaleAbs()的原型为:1dst = cv2.convertScaleAbs(src[, dst[, alpha[, beta]]]) 其中可选参数alpha是伸缩系数，beta是加到结果上的一个值。结果返回uint8类型的图片。 &emsp;&emsp;由于Sobel算子是在两个方向计算的，最后还需要用cv2.addWeighted(…)函数将其组合起来。其函数原型为:1dst = cv2.addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype]]) 其中alpha是第一幅图片中元素的权重，beta是第二个的权重，gamma是加到最后结果上的一个值。 结果展示:原始图像:处理后的图像","categories":[],"tags":[]},{"title":"LSTM Neural Network","slug":"LSTM Neural Network","date":"2019-07-29T07:33:15.000Z","updated":"2019-08-12T05:59:49.636Z","comments":true,"path":"2019/07/29/LSTM Neural Network/","link":"","permalink":"http://yoursite.com/2019/07/29/LSTM Neural Network/","excerpt":"","text":"LSTM Network 长短期时间序列模型介绍核心算法介绍:传统的RNN神经网络:&emsp;&emsp;RNN之所以称为循环神经网络，即”一个序列的当前输出与前面的输出是有相关性”。具体实质体现在后面层数的输入值要加入前面层的输出值，即隐藏层之间不再是不相连的而是有连接的。 展开的递归循环神经网络 &emsp;&emsp;在学习信息情况下，如果相关信息与所需信息之间的差距很小，则RNN可以学习使用过去的信息，表现出较好的训练能力，比如：我们试图预测\"云在天空中\"的最后一次\"天空\",RNN模型就能非常容易的识别出来。但是，如果相关信息与所需要信息之间的距离相差过远时，RNN模型就会很难学习连接这些关系。 LSTM 神经网络:&emsp;&emsp; 长短期时间序列模型(LSTM)是一种特殊的RNN，能够学习长期的依赖性。LSTM的优点就是能够明确旨在避免长期依赖性问题。它能够长时间记住信息，解决了RNN信息距离过长而丧失学习的能力的缺点。所有递归神经网络都具有具有神经网络重复模块链的形式。在标准的RNN中，该重复模块具有非常简单的结构，就是单一的tanh层。 标准RNN中的重复模块包含单个层 &emsp;&emsp;同样LSTM也具有这种类似链的结构，但是重复模块缺失具有不同的结构，它们分别是传输层，遗忘门，输入门，输出门。 LSTM中的重复模块包含四个交互层 1.传输层&emsp;&emsp;传输层水平贯穿图的顶部，直接沿着整个链运行，进行着一些次要的线性交互。从上图中我们可以看出，每个序列索引位置t时刻向前传播中除了和RNN一样具有隐藏状态$h^{(t)}$,还多了另一个隐藏状态，图中上面的横线我们一般称为细胞状态，记为$C^{(t)}$。 传输层中的细胞状态 2.遗忘门&emsp;&emsp;遗忘门是以一定的概率控制是否遗忘上一层的隐藏细胞状态。图中我们可以看出输入的有上一序列的隐藏状态$h^{(t-1)}$和本序列数据$x^{(t)}$,通过激活函数sigmoid，得到遗忘门的输出$f(t)$.由于sigmoid函数的输出$f(t)$是位于[0,1]之间，所以这里的输出$f(t)$就是代表了能否遗忘上一层隐藏细胞状态的概率。该数字表达可以为: f^{(t)}=\\sigma(W_{f}h^{(t-1)}+U_{f}x{(t)}+b_{f})其中$W{f}$,$U{f}$,$b_{f}$分别为线性关系的权重和偏移值。 遗忘门的体系架构 3.输入门输入门层决定我们在单元状态中存储哪些新的信息。其中有两部分组成，一部分称为”输入门层的sigmoid层”,这层决定我们将更新之前的哪些值，输出为$i^{(t)}$，第二部分为”输入门层的tanh层”,这层决定我们创建新的候选值,输出为$a^{(t)}$，最后结合两个创建状态进行更新。该数学表达式可以为: i^{(t)}=\\sigma(W_{i}h^{(t-1)}+U_{i}x{(t)}+b_{i})\\\\ a^{(t)}=\\tanh(W_{a}h^{(t-1)}+U_{a}x{(t)}+b_{a})其中$W{i}$,$U{i}$,$b{i}$,$W{a}$,$U{a}$,$b{a}$分别为线性关系的权重和偏移值。 输入门的体系架构 4.细胞状态更新此过程是决定将旧的细胞状态$C{t-1}$更新至新的细胞状态$C{t}$。在这个过程中首先我们将$f{t}$乘以$C{t-1}$来决定是否忘记之前的事情。其次我们添加了$i{t}*\\tilde{C{t}}$来决定我们需要更新多少新的状态值。即： C^{(t)}=C^{(t-1)}\\odot f^{(t)}+i^{(t)}\\odot a^{(t)} 细胞状态更新体系架构 5.输出门输出门是决定我们要输出的内容。首先，先运行的是一个sigmoid层，决定输出的单元状态属于隐藏状态部分$h^{(t-1)}$,还是本序列数据部分$x^{(t)}$.接着，运行的是tan层，将细胞状态$C_{t}$乘以sigmoid层的输出，从而获取我们所决定的部分。即： o^{(t)}=\\sigma(W_{o}h^{(t-1)}+U_{o}x^(t)+b_{o})\\\\ h^{(t)}= o^{(t)}\\odot\\tanh(C^{(t)})同理其中的$W{o}$,$U{o}$,$b_{o}$分别为线性关系的权重和偏移值。 输出门的体系架构 Keras LSTM 算法模型：LSTM模型构建: 1.首先初始化模型Sequential() 2.接着添加LSTM模型层架构，其中$hiddenLayer$代表为隐藏神经元个数，通俗易懂的解释可以为模型中每个sigmoid层或者tanh层。(注意:LSTM训练模型格式矩阵内容[samples,time_steps,features],简单的说就是[n,1,m]架构，即规定了多少特征输入，一个输出) 3.添加模型全连接层 4.编译模型，选择对应的损失函数和优化器，其中常用的损失函数是MSE,MAE—用于回归，binary-crossentropy—用于二值化分类，categorical-crossentropy—用于标签分类。优化的选择我们常用的自适应学习率优化算法 AdaGrad, AdaDelta,Adam。其他类型不建议使用。 1234model = Sequential()model.add(LSTM(hiddenLayer, input_shape=(train_x.shape[1], train_x.shape[2])))model.add(Dense(1))model.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"]) LSTM模型训练: 将设置好的LSTM模型进行训练，其中$epochs$为循环迭代的次数，$batch size$即每次循环所走的分支数，$validation data$即采用交叉验证的方式对数据进行验证1234567891011121314# Fit networkcheckpointer = ModelCheckpoint(filepath=outputModel, verbose=1, save_best_only=True)history = model.fit( train_x, train_y, epochs=epochs, batch_size=batchSize, validation_data=(test_x, test_y), verbose=2, shuffle=False, callbacks=[checkpointer],)logger.info(model.summary())show_picture(history, imageFolder) LSTM模型预测: 模型预测后的得到的结果为[n,1,m]类型，需要重新reshape得到最终的结果1yhat = model.predict(test_X)","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2019-04-30T03:46:04.519Z","updated":"2019-04-30T03:46:04.519Z","comments":true,"path":"2019/04/30/hello-world/","link":"","permalink":"http://yoursite.com/2019/04/30/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}