{"meta":{"title":"张添豪的博客","subtitle":"莫道君行早，人迹板桥霜","description":null,"author":"Coper","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"python --zip","slug":"python-zip-0","date":"2019-08-14T10:11:42.000Z","updated":"2019-08-14T10:15:42.129Z","comments":true,"path":"2019/08/14/python-zip-0/","link":"","permalink":"http://yoursite.com/2019/08/14/python-zip-0/","excerpt":"","text":"zip()函数介绍: zip()函数接受0个或多个序列作为参数, 返回一个tuple列表. zip()函数具体的工作机制是, 将每个列表中同一位置的元素取出来组成一个元组, 存放到一个列表中, 然后返回这个列表. 举例说明:123456&gt;&gt;&gt; x = [1,2,3]&gt;&gt;&gt; y = ['a','b','c']&gt;&gt;&gt; z = [4,5,6]&gt;&gt;&gt; zip_xyz = zip(x, y, z)&gt;&gt;&gt; print (list(zip_xyz))[(1, 'a', 4), (2, 'b', 5), (3, 'c', 6)] 对于长度不同的seq, zip()函数又怎么处理呢?12345&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b = [4,5,6,7]&gt;&gt;&gt; zip_ab = zip(a, b)&gt;&gt;&gt; print (list(zip_ab))[(1, 4), (2, 5), (3, 6)] 从上面的例子可以看出, 当seq的长度不一致时, zip()会以最短的那个seq为主, 进行处理, 然后将多余的舍弃掉. zip()对只有一个seq的处理:1234&gt;&gt;&gt; c = ['a', 'b', 'c']&gt;&gt;&gt; zip_c = zip(c)&gt;&gt;&gt; print (list(zip_c))[('a',), ('b',), ('c',)] 我们再看一个例子:123456&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = ['a', 'b', 'c']&gt;&gt;&gt; zip_ab = zip(a,b)&gt;&gt;&gt; un_zip = zip(*zip_ab)&gt;&gt;&gt; print (list((un_zip))[(1, 2, 3), ('a', 'b', 'c')] 一般认为这是一个unzip过, 工作原理如下: 在运行zip(zip_ab)之前, zip_ab的值是：[[(1, ‘a’), (2, ‘b’), (3, ‘c’)]], 而zip(zip_ab)就等价于[[zip((1, ‘a’), (2, ‘b’), (3, ‘c’))]], 所以得出结果：[[(1, 2, 3), (‘a’, ‘b’, ‘c’)]]. 再来看一个例子:1234&gt;&gt;&gt; x = [1,'a','b']&gt;&gt;&gt; zip_rx = zip(* [x] * 3)&gt;&gt;&gt; print (list(zip_rx))[(1, 1, 1), ('a', 'a', 'a'), ('b', 'b', 'b')] 首先 [x]生成一个列表的列表: [[1, ‘a’, ‘b’]]，这个列表中只有一个元素[1,’a’,’b’] 其次[x] * 3, 表示将列表中的元素打印三次, 即生成了含有三个元素的列表: [[1, ‘a’, ‘b’]], [[1, ‘a’, ‘b’]], [[1, ‘a’, ‘b’]] 最后是zip( [x] 3)就等价于 zip([1, ‘a’, ‘b’], [1, ‘a’, ‘b’], [1, ‘a’, ‘b’]) 注意:在函数调用中, 使用*list/tuple的方式表示将list/tuple分开, 作为位置参数传递给对应函数, 但前提是对应函数必须支持不定个数的位置参数.","categories":[],"tags":[]},{"title":"Image EdgeDetection Canny","slug":"Image-EdgeDetection-Canny-1","date":"2019-08-12T10:07:37.000Z","updated":"2019-08-12T10:30:25.653Z","comments":true,"path":"2019/08/12/Image-EdgeDetection-Canny-1/","link":"","permalink":"http://yoursite.com/2019/08/12/Image-EdgeDetection-Canny-1/","excerpt":"","text":"图像处理之Canny边缘检测理论介绍:Canny边缘检测是一种流行的边缘检测算法. 它由John F. Canny于1986年开发. 它是一个多阶段算法, 我们将经历每个阶段. 降噪由于边缘检测易受图像中的噪声影响, 因此第一步是使用5x5高斯滤波器去除图像中的噪. 寻找图像的强度梯度然后在水平和垂直方向上用Sobel内核对平滑后的图像进行滤波, 以获得水平方向$(G_{x})$和垂直方向$(G_{y})$的一阶导数. 从这两个图像中, 我们可以找到每个像素的边缘梯度和方向, 渐变方向始终垂直于边缘. 边缘方向角度四舍五入为四个角度中的一个, 表示垂直, 水平和两个对角线(0°,45°,90°和135°). 落入每个颜色区域的边缘方向将被设置为特定角度值,例如, 在[0°,22.5°]或[157.5°,180°]中的θ映射到0°. 如下所示$$EdgeGradient(G)= \\sqrt {G_x ^ 2 + G_y ^ 2}\\Angle(\\theta)= \\tan^{-1}(\\frac {G_y} {G_x})$$ 非最大抑制应用梯度计算后, 从梯度值中提取的边缘仍然非常模. 关于标准3, 应该只对边缘有一个准确的响应. 因此, 非最大抑制可以帮助抑制所有梯度值(通过将它们设置为0), 除了局部最大值, 其指示具有最强烈的强度值变化的位置. 梯度图像中每个像素的算法是: 将当前像素的边缘强度与正和负梯度方向上的像素的边缘强度进行比较. 如果当前像素的边缘强度与具有相同方向的掩模中的其他像素相比是最大的(例如, 指向y方向的像素将与垂直轴上方和下方的像素进行比较), 该值将被保留. 否则, 该值将被抑制. 滞后阈值这个阶段决定哪些边缘都是边缘, 哪些边缘不是边缘. 为此, 我们需要两个阈值, minVal和maxVal. 强度梯度大于maxVal的任何边缘肯定是边缘, 而minVal以下的边缘肯定是非边缘, 因此被丢弃. 位于这两个阈值之间的人是基于其连通性的分类边缘或非边缘. 如果它们连接到“可靠边缘”像素, 则它们被视为边缘的一部分. 否则, 他们也被丢弃.边缘A高于maxVal, 因此被视为”确定边缘”. 虽然边C低于maxVal, 但它连接到边A, 因此也被视为有效边, 我们得到完整的曲线. 但是边缘B虽然高于minVal并且与边缘C的区域相同, 但它没有连接到任何”可靠边缘”, 因此被丢弃. 因此, 我们必须相应地选择minVal和maxVal才能获得正确的结果. 算法原型:&emsp;&emsp;在OpenCV-Python中Canny函数的原型为:1edge = cv2.Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient ]]]) 必要参数: 第一个参数是需要处理的原图像, 该图像必须为单通道的灰度图; 第二个参数是minVal, 最小边缘阈值 第三个参数是maxVal, 最大边缘阈值 推荐的minVal和maxVal阈值之间的比例为1:3或者1:2, 可选参数中apertureSize就是Sobel算子的大小. 而L2gradient参数是一个布尔值, 如果为真, 则使用更精确的L2范数进行计算(即两个方向的倒数的平方和再开放), 否则使用L1范数(直接将两个方向导数的绝对值相加). 代码展示:import cv2 import numpy as np from matplotlib import pyplot as plt img = cv2.imread('messi5.jpg',0) edges = cv2.Canny(img,100,200) plt.subplot(121),plt.imshow(img,cmap = 'gray') plt.title('Original Image'), plt.xticks([]), plt.yticks([]) plt.subplot(122),plt.imshow(edges,cmap = 'gray') plt.title('Edge Image'), plt.xticks([]), plt.yticks([]) plt.show() 结果展示:原始图像:处理后图像:","categories":[],"tags":[]},{"title":"Image EdgeDetection Sobel","slug":"Image-EdgeDetection-Sobel","date":"2019-08-09T10:13:19.000Z","updated":"2019-08-12T01:13:01.618Z","comments":true,"path":"2019/08/09/Image-EdgeDetection-Sobel/","link":"","permalink":"http://yoursite.com/2019/08/09/Image-EdgeDetection-Sobel/","excerpt":"","text":"图像处理之Sobel算子算法原型:&emsp;&emsp;Sobel算子依然是一种过滤器，只是其是带有方向的。在OpenCV-Python中，使用Sobel的算子的函数原型如下:1dst = cv2.Sobel(src, ddepth, dx, dy[, ksize[, scale[, delta[, borderType]]]]])) 前四个是必须的参数: 第一个参数是需要处理的图像； 第二个参数是图像的深度，如cv2.CV_16S, cv2.CV_64F。目标图像的深度必须大于等于原图像的深度； 第三个dx和dy表示的是求导的阶数，0表示这个方向上没有求导，一般为0、1、2。 其后是可选的参数: ksize是Sobel算子的大小，必须为1、3、5、7。 scale是缩放导数的比例常数，默认情况下没有伸缩系数； delta是一个可选的增量，将会加到最终的dst中，同样，默认情况下没有额外的值加到dst中； borderType是判断图像边界的模式。这个参数默认值为cv2.BORDER_DEFAULT。 代码展示:123456789101112131415161718192021 #coding=utf-8import cv2import numpy as np img = cv2.imread(\"D:/lion.jpg\", 0) x = cv2.Sobel(img,cv2.CV_16S,1,0)y = cv2.Sobel(img,cv2.CV_16S,0,1) absX = cv2.convertScaleAbs(x) # 转回uint8absY = cv2.convertScaleAbs(y) dst = cv2.addWeighted(absX,0.5,absY,0.5,0) cv2.imshow(\"absX\", absX)cv2.imshow(\"absY\", absY) cv2.imshow(\"Result\", dst) cv2.waitKey(0)cv2.destroyAllWindows() 注释:&emsp;&emsp;在Sobel函数的第二个参数这里使用了cv2.CV_16S。因为OpenCV文档中对Sobel算子的介绍中有这么一句：“in the case of 8-bit input images it will result in truncated derivatives”。即Sobel函数求完导数后会有负值，还有会大于255的值。而原图像是uint8，即8位无符号数，所以Sobel建立的图像位数不够，会有截断。因此要使用16位有符号的数据类型，即cv2.CV_16S。 &emsp;&emsp;在经过处理后，别忘了用convertScaleAbs()函数将其转回原来的uint8形式。否则将无法显示图像，而只是一副灰色的窗口。convertScaleAbs()的原型为:1dst = cv2.convertScaleAbs(src[, dst[, alpha[, beta]]]) 其中可选参数alpha是伸缩系数，beta是加到结果上的一个值。结果返回uint8类型的图片。 &emsp;&emsp;由于Sobel算子是在两个方向计算的，最后还需要用cv2.addWeighted(…)函数将其组合起来。其函数原型为:1dst = cv2.addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype]]) 其中alpha是第一幅图片中元素的权重，beta是第二个的权重，gamma是加到最后结果上的一个值。 结果展示:原始图像:处理后的图像","categories":[],"tags":[]},{"title":"LSTM Neural Network","slug":"LSTM Neural Network","date":"2019-07-29T07:33:15.000Z","updated":"2019-08-12T05:59:49.636Z","comments":true,"path":"2019/07/29/LSTM Neural Network/","link":"","permalink":"http://yoursite.com/2019/07/29/LSTM Neural Network/","excerpt":"","text":"LSTM Network 长短期时间序列模型介绍核心算法介绍:传统的RNN神经网络:&emsp;&emsp;RNN之所以称为循环神经网络，即”一个序列的当前输出与前面的输出是有相关性”。具体实质体现在后面层数的输入值要加入前面层的输出值，即隐藏层之间不再是不相连的而是有连接的。 展开的递归循环神经网络&emsp;&emsp;在学习信息情况下，如果相关信息与所需信息之间的差距很小，则RNN可以学习使用过去的信息，表现出较好的训练能力，比如：我们试图预测”云在天空中”的最后一次”天空”,RNN模型就能非常容易的识别出来。但是，如果相关信息与所需要信息之间的距离相差过远时，RNN模型就会很难学习连接这些关系。 LSTM 神经网络:&emsp;&emsp; 长短期时间序列模型(LSTM)是一种特殊的RNN，能够学习长期的依赖性。LSTM的优点就是能够明确旨在避免长期依赖性问题。它能够长时间记住信息，解决了RNN信息距离过长而丧失学习的能力的缺点。所有递归神经网络都具有具有神经网络重复模块链的形式。在标准的RNN中，该重复模块具有非常简单的结构，就是单一的tanh层。 标准RNN中的重复模块包含单个层&emsp;&emsp;同样LSTM也具有这种类似链的结构，但是重复模块缺失具有不同的结构，它们分别是传输层，遗忘门，输入门，输出门。LSTM中的重复模块包含四个交互层 1.传输层&emsp;&emsp;传输层水平贯穿图的顶部，直接沿着整个链运行，进行着一些次要的线性交互。从上图中我们可以看出，每个序列索引位置t时刻向前传播中除了和RNN一样具有隐藏状态$h^{(t)}$,还多了另一个隐藏状态，图中上面的横线我们一般称为细胞状态，记为$C^{(t)}$。 传输层中的细胞状态 2.遗忘门&emsp;&emsp;遗忘门是以一定的概率控制是否遗忘上一层的隐藏细胞状态。图中我们可以看出输入的有上一序列的隐藏状态$h^{(t-1)}$和本序列数据$x^{(t)}$,通过激活函数sigmoid，得到遗忘门的输出$f(t)$.由于sigmoid函数的输出$f(t)$是位于[0,1]之间，所以这里的输出$f(t)$就是代表了能否遗忘上一层隐藏细胞状态的概率。该数字表达可以为:$$f^{(t)}=\\sigma(W_{f}h^{(t-1)}+U_{f}x{(t)}+b_{f})$$ 其中$W_{f}$,$U_{f}$,$b_{f}$分别为线性关系的权重和偏移值。 遗忘门的体系架构 3.输入门输入门层决定我们在单元状态中存储哪些新的信息。其中有两部分组成，一部分称为”输入门层的sigmoid层”,这层决定我们将更新之前的哪些值，输出为$i^{(t)}$，第二部分为”输入门层的tanh层”,这层决定我们创建新的候选值,输出为$a^{(t)}$，最后结合两个创建状态进行更新。该数学表达式可以为:$$i^{(t)}=\\sigma(W_{i}h^{(t-1)}+U_{i}x{(t)}+b_{i})\\a^{(t)}=\\tanh(W_{a}h^{(t-1)}+U_{a}x{(t)}+b_{a})$$其中$W_{i}$,$U_{i}$,$b_{i}$,$W_{a}$,$U_{a}$,$b_{a}$分别为线性关系的权重和偏移值。 输入门的体系架构 4.细胞状态更新此过程是决定将旧的细胞状态$C_{t-1}$更新至新的细胞状态$C_{t}$。在这个过程中首先我们将$f_{t}$乘以$C_{t-1}$来决定是否忘记之前的事情。其次我们添加了$i_{t}*\\tilde{C_{t}}$来决定我们需要更新多少新的状态值。即：$$C^{(t)}=C^{(t-1)}\\odot f^{(t)}+i^{(t)}\\odot a^{(t)}$$ 细胞状态更新体系架构 5.输出门输出门是决定我们要输出的内容。首先，先运行的是一个sigmoid层，决定输出的单元状态属于隐藏状态部分$h^{(t-1)}$,还是本序列数据部分$x^{(t)}$.接着，运行的是tan层，将细胞状态$C_{t}$乘以sigmoid层的输出，从而获取我们所决定的部分。即：$$o^{(t)}=\\sigma(W_{o}h^{(t-1)}+U_{o}x^(t)+b_{o})\\h^{(t)}= o^{(t)}\\odot\\tanh(C^{(t)})$$同理其中的$W_{o}$,$U_{o}$,$b_{o}$分别为线性关系的权重和偏移值。 输出门的体系架构 Keras LSTM 算法模型：LSTM模型构建: 1.首先初始化模型Sequential() 2.接着添加LSTM模型层架构，其中$hiddenLayer$代表为隐藏神经元个数，通俗易懂的解释可以为模型中每个sigmoid层或者tanh层。(注意:LSTM训练模型格式矩阵内容[samples,time_steps,features],简单的说就是[n,1,m]架构，即规定了多少特征输入，一个输出) 3.添加模型全连接层 4.编译模型，选择对应的损失函数和优化器，其中常用的损失函数是MSE,MAE–用于回归，binary-crossentropy–用于二值化分类，categorical-crossentropy–用于标签分类。优化的选择我们常用的自适应学习率优化算法 AdaGrad, AdaDelta,Adam。其他类型不建议使用。 1234model = Sequential()model.add(LSTM(hiddenLayer, input_shape=(train_x.shape[1], train_x.shape[2])))model.add(Dense(1))model.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"]) LSTM模型训练: 将设置好的LSTM模型进行训练，其中$epochs$为循环迭代的次数，$batch size$即每次循环所走的分支数，$validation data$即采用交叉验证的方式对数据进行验证1234567891011121314# Fit networkcheckpointer = ModelCheckpoint(filepath=outputModel, verbose=1, save_best_only=True)history = model.fit( train_x, train_y, epochs=epochs, batch_size=batchSize, validation_data=(test_x, test_y), verbose=2, shuffle=False, callbacks=[checkpointer],)logger.info(model.summary())show_picture(history, imageFolder) LSTM模型预测: 模型预测后的得到的结果为[n,1,m]类型，需要重新reshape得到最终的结果1yhat = model.predict(test_X)","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2019-04-30T03:46:04.519Z","updated":"2019-04-30T03:46:04.519Z","comments":true,"path":"2019/04/30/hello-world/","link":"","permalink":"http://yoursite.com/2019/04/30/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}